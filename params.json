{"tagline":"Provides a fast, cross-Ruby implementation of the  ngramdistance distance algorithm","name":"Ngramdistance-ffi","google":"","body":"ngramdistance-ffi\r\n===============\r\n\r\nConverted to FFI by Bali for Ruby portability.\r\n\r\nThis gem originally based on ngram distance or similarity algorithm from Proceedings of the Twelfth International \r\nConference on String Processing and Information Retrieval (SPIRE 2005).\r\n\r\n* This program was ported by hand from lucene-3.0.2. (lucene is Java product)\r\n* It supports only ngram distance algorithm.\r\n\r\n\r\nTested on:\r\n\r\n* MRI 1.9.2\r\n\r\nKnown Issues\r\n============\r\n* The C extension uses `char*` strings, and so Unicode strings will give incorrect distances.\r\n\r\nIncluding in Gemfile\r\n====================\r\n\r\n    gem 'ngramdistance-ffi', :require => 'ngramdistance'\r\nOriginal README\r\n===============\r\n\r\nN-Gram version of edit distance based on paper by Grzegorz Kondrak, \r\n\"N-gram similarity and distance\". Proceedings of the Twelfth International \r\nConference on String Processing and Information Retrieval (SPIRE 2005), pp. 115-126, \r\nBuenos Aires, Argentina, November 2005. \r\nhttp://www.cs.ualberta.ca/~kondrak/papers/spire05.pdf\r\n\r\nThis implementation uses the position-based optimization to compute partial\r\nmatches of n-gram sub-strings and adds a null-character prefix of size n-1 \r\nso that the first character is contained in the same number of n-grams as \r\na middle character.  Null-character prefix matches are discounted so that \r\nstrings with no matching characters will return a distance of 0.\r\n\r\nThe module has a\r\nfollowing functions:\r\n\r\n* distance\r\n----------\r\n    require 'ngramdistance'\r\n    NGramDistance.distance(\"string1\", \"string1\") # returns 1.0\r\n    NGramDistance.distance(\"university\", \"univearsitty\",3) # returns 0.750000\r\n    \r\nmethod signature is distance(source,target,ngram=3,mode=PROPOSITIONAL)\r\n\r\nThird argument is the ngram granularity.\r\n* 1 -> unigram\r\n* 2 -> bigram\r\n* 3 -> trigram\r\n\r\ndefault argument is 3 (tri-gram)\r\n\r\nFourth argument is mode of operation. We have 3 modes defined\r\n* PROPOSITIONAL=0\r\n\tPropositional Computes the distance between n-grams with partial matching\r\n* BINARY=1\r\n\tOnly considers 2 n-grams match when they are exactly the same\r\n* COMPLEX=2\r\n\tUses ngramdistance with Binary option and 1-gram match for the n-gram match. \r\n\r\ndefault is PROPOSITIONAL mode.\r\n\r\n* token_sort_distance\r\n---------------------\t\r\n\trequire 'ngramdistance'\r\n    NGramDistance.token_sort_distance(\"hello bello\", \"bello hello\") # returns 1.0\r\n\r\nThe token sort approach involves tokenizing the string in question, sorting the tokens alphabetically, and then joining them back into a string. For example:\r\n\t\r\n\t\"new york mets vs atlanta braves\"   →→  \"atlanta braves mets new vs york\" \r\n\t\r\nWe then compare the transformed strings with a simple distance(). That nicely solves our ordering problem, as our helper function below indicates:\r\n\t\r\n\tNGramDistance.token_sort_distance(\"New York Mets vs Atlanta Braves\", \"Atlanta Braves vs New York Mets\") ⇒ 1.0\r\n\t\r\nmethod signature is token_sort_distance(source,target,regex=' ',ngram=3,mode=PROPOSITIONAL)\r\nthe arguments are same as distance function but with extra argument regex, character or string to split source and target\r\n\r\n* token_set_distance\r\n--------------------\t\r\n\trequire 'ngramdistance'\r\n    NGramDistance.token_sort_distance(\"hello\", \"hello hello\") # returns 1.0\r\n    \r\n\r\nThe token set approach is similar, but a little bit more flexible. Here, we tokenize both strings, but instead of immediately sorting and comparing, we split the tokens into two groups: intersection and remainder. We use those sets to build up a comparison string.\r\nHere is an illustrative example:\r\n\ts1 = \"mariners vs angels\"\r\n\ts2 = \"los angeles angels of anaheim at seattle mariners\"\r\n\r\nUsing the token sort method isn't that helpful, because the second (longer) string has too many extra tokens that get interleaved with the sort. We'd end up comparing:\r\n\r\n\tt1 = \"angels mariners vs\"\r\n\tt2 = \"anaheim angeles angels los mariners of seattle vs\"\r\n\r\nNot very useful. Instead, the set method allows us to detect that \"angels\" and \"mariners\" are common to both strings, and separate those out (the set intersection). Now we construct and compare strings of the following form\r\n\r\n\tt0 = [SORTED_INTERSECTION]\r\n\tt1 = [SORTED_INTERSECTION] + [SORTED_REST_OF_STRING1]\r\n\tt2 = [SORTED_INTERSECTION] + [SORTED_REST_OF_STRING2]\r\n\r\nAnd then compare each pair.\r\n\r\nThe intuition here is that because the SORTED_INTERSECTION component is always exactly the same, the scores increase when (a) that makes up a larger percentage of the full string, and (b) the string remainders are more similar. In our example\r\n\r\n\tt0 = \"angels mariners\"\r\n\tt1 = \"angels mariners vs\"\r\n\tt2 = \"angels mariners anaheim angels\"\r\n\tNGramDistance.distance(t0, t1) ⇒ 0.83333\r\n\tNGramDistance.distance(t0, t2) ⇒ 0.4838\r\n\tNGramDistance.distance(t1, t2) ⇒ 0.54828\r\n\tNGramDistance.token_set_distance(t0,t2) ⇒ 0.6521\r\n\r\n\r\n\tNGramDistance.token_set_distance(\"hello hello world\", \"hello world\") ⇒ 1.0\r\n\r\nmethod signature is token_set_distance(source,target,regex=' ',ngram=3,mode=PROPOSITIONAL)\r\nthe arguments are same as distance function but with extra argument regex, character or string to split source and target\r\n\t\r\n\r\n\r\n\r\n\r\nAuthor\r\n======\r\n\r\n* Copyright (c) 2012, Bali (mailbali@gmail.com)\r\n* I ported from java source code of lucene-3.0.2.\r\n\r\nLicense\r\n=======\r\n* Apache  2.0 LICENSE\r\n\r\n","note":"Don't delete this file! It's used internally to help with page regeneration."}